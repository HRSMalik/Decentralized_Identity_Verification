{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f56b492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/malik-harris/tekhqs/didenv/Decentralized_Identity_Verification'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2168b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"Model/best_kyc_siamese.onnx\"\n",
    "settings_path = \"zk/settings.json\"\n",
    "compiled_model_path = \"zk/network.compiled\"\n",
    "pk_path = \"zk/key.pk\"\n",
    "vk_path = \"zk/key.vk\"\n",
    "witness_path = \"zk/witness.json\"\n",
    "data_path = \"zk/input.json\"\n",
    "os.makedirs(\"zk\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- Paths\n",
    "inference_dir = \"inference\"\n",
    "doc_img_path = None\n",
    "selfie_img_path = None\n",
    "\n",
    "# --- Find one doc + selfie image pair\n",
    "for file in os.listdir(inference_dir):\n",
    "    if any(x in file.lower() for x in [\"id\", \"passport\", \"national\"]) and doc_img_path is None:\n",
    "        doc_img_path = os.path.join(inference_dir, file)\n",
    "    elif \"selfie\" in file.lower() and selfie_img_path is None:\n",
    "        selfie_img_path = os.path.join(inference_dir, file)\n",
    "\n",
    "assert doc_img_path and selfie_img_path, \"No valid doc/selfie image found.\"\n",
    "\n",
    "# --- Same transform as training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- Load & transform\n",
    "doc_tensor = transform(Image.open(doc_img_path).convert(\"RGB\")).unsqueeze(0)  # shape: [1, 3, 112, 112]\n",
    "selfie_tensor = transform(Image.open(selfie_img_path).convert(\"RGB\")).unsqueeze(0)\n",
    "\n",
    "# --- Flatten tensors to 1D lists\n",
    "doc_array = doc_tensor.flatten().tolist()\n",
    "selfie_array = selfie_tensor.flatten().tolist()\n",
    "\n",
    "# --- Format for EZKL\n",
    "data = {\n",
    "    \"input_data\": [doc_array, selfie_array]\n",
    "}\n",
    "\n",
    "# --- Save to JSON\n",
    "with open(\"zk/input.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "\n",
    "print(f\"âœ… Saved input to zk/input.json:\\nDoc: {doc_img_path}\\nSelfie: {selfie_img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import json\n",
    "\n",
    "# # Create dummy input tensors\n",
    "# doc_tensor = torch.rand(1, 3, 224, 224)\n",
    "# selfie_tensor = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# # Flatten and convert tensors to lists\n",
    "# doc_array = doc_tensor.flatten().tolist()\n",
    "# selfie_array = selfie_tensor.flatten().tolist()\n",
    "\n",
    "# # Prepare the input data dictionary\n",
    "# data = {\n",
    "#     \"input_data\": [doc_array, selfie_array]\n",
    "# }\n",
    "\n",
    "# # Save to a JSON file\n",
    "# with open(\"zk/input.json\", \"w\") as f:\n",
    "#     json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b636138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load the ONNX model\n",
    "session = ort.InferenceSession(\"Model/best_kyc_siamese.onnx\")\n",
    "\n",
    "# Prepare dummy inputs\n",
    "inputs = {\n",
    "    \"doc_img\": np.random.rand(1, 3, 112, 112).astype(np.float32),\n",
    "    \"selfie_img\": np.random.rand(1, 3, 112, 112).astype(np.float32)\n",
    "}\n",
    "\n",
    "# Run a forward pass\n",
    "outputs = session.run(None, inputs)\n",
    "print(\"Sigmoid output (probability):\", outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7f74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c7a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args = ezkl.PyRunArgs()\n",
    "run_args.input_visibility = \"private\"       \n",
    "run_args.param_visibility = \"private\"         \n",
    "run_args.output_visibility = \"public\"       \n",
    "run_args.num_inner_cols = 2                 # Leave at 2 unless you have perf issues\n",
    "run_args.logrows = 16\n",
    "run_args.input_scale = 8                \n",
    "run_args.param_scale = 8\n",
    "run_args.variables = [(\"batch_size\", 1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ezkl.gen_settings(model_path, settings_path,py_run_args=run_args)\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await ezkl.calibrate_settings(data_path, model_path, settings_path, target=\"resources\", scales = [1, 2, 4, 8, 16] )\n",
    "assert res == True\n",
    "print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ezkl.compile_circuit(model_path, compiled_model_path, settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await ezkl.get_srs(settings_path)\n",
    "print(\"SRS generated:\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "print(\"Witness generated:\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765b87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export ENABLE_ICICLE_GPU=true\n",
    "!export ICICLE_SMALL_K=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd3e689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dynamic lookup has 3 blocks\n",
      "dynamic lookup has 3 blocks\n",
      "dynamic lookup has 3 blocks\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        \n",
    "    )\n",
    "\n",
    "print(\"Setup completed:\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "didenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
